{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8FAgwCBs7NvR",
   "metadata": {
    "id": "8FAgwCBs7NvR"
   },
   "outputs": [],
   "source": [
    "!pip install transformers &> /dev/null\n",
    "!pip install datasets &> /dev/null\n",
    "!pip install razdel &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5642ac",
   "metadata": {
    "id": "4a5642ac"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from razdel import sentenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8L5d237HAD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de8L5d237HAD",
    "outputId": "e4b18d95-1063-4532-9414-06d1f8f3d351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#для колаб\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2351ffc",
   "metadata": {
    "id": "b2351ffc"
   },
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f28071",
   "metadata": {
    "id": "d8f28071"
   },
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    string = re.sub('[^а-яА-Яa-zA-Z0-9)(+-/@.,# \\n]', '', string)\n",
    "    string = re.sub('\\)+', ')', string)\n",
    "    string = re.sub('\\(+', '(', string)\n",
    "    string = re.sub('\\++', '+', string)\n",
    "    string = re.sub('\\-+', '-', string)\n",
    "    string = re.sub('\\/+', '/', string)\n",
    "    string = re.sub('\\@+', '@', string)\n",
    "    string = re.sub('\\.+', '.', string)\n",
    "    string = re.sub('\\,+', ',', string)\n",
    "    string = re.sub('\\#+', '#', string) #дискорд\n",
    "    string = re.sub('\\ +', ' ', string)\n",
    "    string = re.sub('/\\n', '\\n', string) #подумать еще над этим\n",
    "    string = re.sub('\\n+', '\\n', string)\n",
    "    \n",
    "    return string\n",
    "\n",
    "def to_sents(text):\n",
    "    \n",
    "    paragraphs = [p for p in text.split('\\n')]\n",
    "    full_list = []\n",
    "    for paragraph in paragraphs:\n",
    "        sents = list(sentenize(paragraph)) #использует razdel\n",
    "        full_list.append(sents)\n",
    "    full_list = [sent for sents in full_list for sent in sents if sent]\n",
    "    full_list = [sent.text for sent in full_list if sent.text]\n",
    "    \n",
    "    return full_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aecca4",
   "metadata": {
    "id": "f7aecca4"
   },
   "source": [
    "## Загрузка трансформера-классификатора единичных предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ebb8761",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ebb8761",
    "outputId": "19d0c962-c01b-4ba9-ea19-91de80b6b704"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at rubert-tiny-finetuned-class were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#загружаем эмбеддер\n",
    "inference_checkpoint = 'rubert-tiny-finetuned-class'\n",
    "model = AutoModel.from_pretrained(inference_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(inference_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "255e4c6d",
   "metadata": {
    "id": "255e4c6d"
   },
   "outputs": [],
   "source": [
    "def embed(x):\n",
    "    if len(x) == 0:\n",
    "        x = 'Пусто' \n",
    "        \n",
    "    tokenized_x = tokenizer(x, padding = True,\n",
    "                             truncation = True,\n",
    "                             max_length = 512,\n",
    "                             return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():      \n",
    "        model_output = model(**tokenized_x)\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c59f39",
   "metadata": {
    "id": "c4c59f39"
   },
   "source": [
    "## Выбор объектов и создание эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f745654",
   "metadata": {
    "id": "3f745654"
   },
   "outputs": [],
   "source": [
    "#загрузка данных\n",
    "df = pd.read_csv('train/train.csv')\n",
    "df['description_razdel'] = df['description'].apply(lambda x: to_sents(clean(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#формируем сбалансированную выборку\n",
    "n = 5000\n",
    "df_to_train_big_balanced = pd.concat([df[(df['category'] == 'Бытовая электроника') & (df['is_bad'] == 0)].sample(n),\n",
    "                         df[(df['category'] == 'Бытовая электроника') & (df['is_bad'] == 1)].sample(n),\n",
    "                         df[(df['category'] == 'Для бизнеса') & (df['is_bad'] == 0)].sample(2*n),\n",
    "                         df[(df['category'] == 'Для бизнеса') & (df['is_bad'] == 1)], #и так мало\n",
    "                         df[(df['category'] == 'Для дома и дачи') & (df['is_bad'] == 0)].sample(n),\n",
    "                         df[(df['category'] == 'Для дома и дачи') & (df['is_bad'] == 1)].sample(n),\n",
    "                         df[(df['category'] == 'Животные') & (df['is_bad'] == 0)].sample(n),\n",
    "                         df[(df['category'] == 'Животные') & (df['is_bad'] == 1)].sample(n),\n",
    "                         df[(df['category'] == 'Личные вещи') & (df['is_bad'] == 0)].sample(2*n),\n",
    "                         df[(df['category'] == 'Личные вещи') & (df['is_bad'] == 1)].sample(2*n),\n",
    "                         df[(df['category'] == 'Недвижимость') & (df['is_bad'] == 0)].sample(n),\n",
    "                         df[(df['category'] == 'Недвижимость') & (df['is_bad'] == 1)].sample(n),\n",
    "                         df[(df['category'] == 'Работа') & (df['is_bad'] == 0)].sample(2*n),\n",
    "                         df[(df['category'] == 'Работа') & (df['is_bad'] == 1)].sample(2*n),\n",
    "                         df[(df['category'] == 'Транспорт') & (df['is_bad'] == 0)].sample(n),\n",
    "                         df[(df['category'] == 'Транспорт') & (df['is_bad'] == 1)].sample(n),\n",
    "                         df[(df['category'] == 'Услуги') & (df['is_bad'] == 0)].sample(2*n),\n",
    "                         df[(df['category'] == 'Услуги') & (df['is_bad'] == 1)].sample(2*n),\n",
    "                         df[(df['category'] == 'Хобби и отдых') & (df['is_bad'] == 0)].sample(n),\n",
    "                         df[(df['category'] == 'Хобби и отдых') & (df['is_bad'] == 1)].sample(n)]\n",
    "                                  ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6ade0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "c6a6ade0",
    "outputId": "bf90b4be-b8b7-4038-a43a-622b27b9b693"
   },
   "outputs": [],
   "source": [
    "#создаем эмбеддинги - занимает время\n",
    "tqdm.pandas()\n",
    "df['embeddings'] = df['description_razdel'].progress_apply(embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd189720",
   "metadata": {},
   "source": [
    "## Создание датасетов из эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41a18e",
   "metadata": {
    "id": "cd41a18e"
   },
   "outputs": [],
   "source": [
    "#создаем df с X и y и бьем его на части\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_embeddings = df[['embeddings', 'is_bad']]\n",
    "train, test = train_test_split(df_embeddings, test_size=0.2)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa170f",
   "metadata": {
    "id": "24fa170f"
   },
   "outputs": [],
   "source": [
    "class EmbeddingsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_df):\n",
    "        self.df = input_df\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df['embeddings'][idx]\n",
    "        y = self.df['is_bad'][idx]\n",
    "        return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89588f5d",
   "metadata": {
    "id": "89588f5d"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    embedding_tensors = []\n",
    "    labels = []\n",
    "    \n",
    "    for item in batch:\n",
    "        x, y = item\n",
    "        embedding_tensors.append(x)\n",
    "        labels.append(y)\n",
    "\n",
    "    x = pad_sequence(embedding_tensors, batch_first=True)\n",
    "    y = torch.tensor(labels)\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fff24",
   "metadata": {
    "id": "9e6fff24"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, \n",
    "                                               shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128, \n",
    "                                             shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5ae23",
   "metadata": {},
   "source": [
    "# Модель и обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eeef5a",
   "metadata": {
    "id": "24eeef5a"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):   \n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        embedding_dim = 312\n",
    "        hidden_dim = 100\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            batch_first=True, \n",
    "                            bidirectional=True)  \n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim*2, 2)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.lstm(x)[1][0]\n",
    "        x = x.permute(1, 0, -1)\n",
    "        x = torch.cat((torch.chunk(x, 2, dim=1)[0], \n",
    "                       torch.chunk(x, 2, dim=1)[1]), dim=2)\n",
    "        x = x.squeeze(dim=1)\n",
    "        x = self.linear(x)\n",
    "        scores = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a5af2d",
   "metadata": {
    "id": "e9a5af2d"
   },
   "outputs": [],
   "source": [
    "class PLModel(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_accuracy = torchmetrics.Accuracy()\n",
    "        \n",
    "        self.val_auroc = torchmetrics.AUROC(num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.exp(self.model(x))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):      \n",
    "        x, y = batch\n",
    "        neg_logs = self.model(x)\n",
    "        loss = loss_fn(neg_logs, y)\n",
    "        \n",
    "        probs = torch.exp(neg_logs)\n",
    "        train_accuracy = self.train_accuracy(probs, y)\n",
    "    \n",
    "        self.log(\"train loss\", loss, prog_bar=True)\n",
    "        self.log(\"train acc\", train_accuracy, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):   \n",
    "        x, y = batch\n",
    "        neg_logs = self.model(x)\n",
    "        loss = loss_fn(neg_logs, y)\n",
    "        \n",
    "        probs = torch.exp(neg_logs)\n",
    "        val_accuracy = self.val_accuracy(probs, y)\n",
    "        val_auroc = self.val_auroc(probs, y)\n",
    " \n",
    "        self.log(\"val loss\", loss, prog_bar=True)\n",
    "        self.log(\"val acc\", val_accuracy, prog_bar=True)\n",
    "        self.log(\"val auroc\", val_auroc, prog_bar=True)  \n",
    "        \n",
    "    def training_epoch_end(self, *args, **kwargs):\n",
    "        self.train_accuracy.reset()\n",
    "        \n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log('val acc', self.val_accuracy.compute(), prog_bar=True)\n",
    "        self.val_accuracy.reset()\n",
    "        \n",
    "        self.log('val aucroc', self.val_auroc.compute(), prog_bar=True)\n",
    "        self.val_auroc.reset()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters())\n",
    "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "        \n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49836075",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTMClassifier()\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"lstm_checkpoints\", \n",
    "                                      save_top_k=15, \n",
    "                                      monitor=\"val auroc\"\n",
    "                                     )\n",
    "\n",
    "pl_model = PLModel(lstm_model)\n",
    "\n",
    "logger = TensorBoardLogger('lstm_logs', default_hp_metric=False)\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val auroc\", min_delta=0.00, patience=5, \n",
    "    verbose=False, mode=\"max\"\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=15, callbacks=[checkpoint_callback, early_stop_callback], \n",
    "    logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2a80c",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "",
      "d9cd2fd3ee6d4dfeac80c3d540637140"
     ]
    },
    "id": "d6d2a80c",
    "outputId": "b27decda-7365-414e-e1d2-5ccc1376e983"
   },
   "outputs": [],
   "source": [
    "#нужно, чтобы график обучения нормально выглядел, как следует\n",
    "trainer.fit(pl_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7570ed57",
   "metadata": {
    "id": "7570ed57",
    "outputId": "d07b20bb-1742-44c0-9222-1df4809e9da1"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lstm_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7db38",
   "metadata": {
    "id": "06e7db38"
   },
   "outputs": [],
   "source": [
    "torch.save(pl_model.model.state_dict(), 'state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b2a2b",
   "metadata": {
    "id": "b21b2a2b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90aa89",
   "metadata": {
    "id": "cc90aa89"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTM_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
